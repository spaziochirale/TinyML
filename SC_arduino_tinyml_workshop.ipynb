{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_arduino_tinyml_workshop.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaziochirale/TinyML/blob/master/SC_arduino_tinyml_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92-4Hjy7kA8"
      },
      "source": [
        "<a href=\"https://www.arduino.cc/\"><img src=\"https://raw.githubusercontent.com/sandeepmistry/aimldevfest-workshop-2019/master/images/Arduino_logo_R_highquality.png\" width=200/></a>\n",
        "# Tiny ML su Arduino\n",
        "## Riconoscimento delle Gesture\n",
        "Versione tradotta dal lavoro originale di:\n",
        "\n",
        " * Sandeep Mistry - Arduino\n",
        " * Don Coleman - Chariot Solutions\n",
        "\n",
        "\n",
        "https://github.com/arduino/ArduinoTensorFlowLiteTutorials/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDA8AK7QOq-"
      },
      "source": [
        "## Predisposizione dell'ambiente di esecuzione\n",
        "\n",
        "Google Colaboratory ha già tutte le librerie Python che ci servono, installate, per cui non è necessario scaricare alcun package.\n",
        "L'istruzione che segue, si limita ad installare sul sistema operativo l'utility Unix \"**xdd**\" che potrebbe non essere presente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2gs-PL4xDkZ"
      },
      "source": [
        "# Setup environment\n",
        "!apt-get -qq install xxd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lwkeshJk7dg"
      },
      "source": [
        "# Carichiamo i dati campionati tramite Arduino\n",
        "\n",
        "1. Sulla sinistra di questa pagina web è presente un menù a colonna con diverse icone\n",
        "1. Selezionare l'icona a forma di \"cartella\" per aprire l'area che rappresenta la cartella '/content' del server che ospita questo notebook.\n",
        "1. Trascinare i file  `punch.csv` e `flex.csv` dal computer su quest'area per caricarli all'interno dell'ambiente colab.\n",
        "\n",
        "I file rimarranno registrati sul server finché la sessione corrente è attiva. Se viene persa la connessione con il server colab oppure viene chiusa la pagina del browser, lo spazio virtuale allocato sarà recuperato dal sistema, i file trasferiti non ci saranno più, e occorrerà ricaricarli dopo aver avviato la nuova sessione di lavoro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh9yve14gUyD"
      },
      "source": [
        "# Visualizziamo graficamente i dati (opzionale)\n",
        "\n",
        "Costruiamo due grafici separati per i campioni ricavati dall'accelerometro e dal giroscopio, poiché i due insiemi di dati hanno unità di misura e scala di valori differenti."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I65ukChEgyNp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# lista delle gesture che abbiamo campionato\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"flex\",\n",
        "]\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  print(\"Gesture:\",GESTURES[gesture_index])\n",
        "  filename = \"/content/\" + gesture + \".csv\"\n",
        "\n",
        "  df = pd.read_csv(filename)\n",
        "\n",
        "  index = range(1, len(df['aX']) + 1)\n",
        "\n",
        "  plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "  plt.plot(index, df['aX'], 'g', label='x', linestyle='solid')\n",
        "  plt.plot(index, df['aY'], 'b', label='y', linestyle='solid')\n",
        "  plt.plot(index, df['aZ'], 'r', label='z', linestyle='solid')\n",
        "  plt.title(\"Acceleration\")\n",
        "  plt.xlabel(\"Sample #\")\n",
        "  plt.ylabel(\"Acceleration (G)\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(index, df['gX'], 'g', label='x', linestyle='solid')\n",
        "  plt.plot(index, df['gY'], 'b', label='y', linestyle='solid')\n",
        "  plt.plot(index, df['gZ'], 'r', label='z', linestyle='solid')\n",
        "  plt.title(\"Gyroscope\")\n",
        "  plt.xlabel(\"Sample #\")\n",
        "  plt.ylabel(\"Gyroscope (deg/sec)\")\n",
        "  plt.legend()\n",
        "  plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxUeYPNQbOg"
      },
      "source": [
        "# Addestriamo la Rete Neurale\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxk414PU3oy3"
      },
      "source": [
        "## Parsing e preparazione dei dati\n",
        "\n",
        "Le istruzioni che seguono effettuano il parsing dei dati csv e li trasformano in un formato che sarà utilizzato per addestrare la rete neurale di tipo \"denso\" o \"fully connected\".\n",
        "\n",
        "La lista `GESTURES` viene aggiornata con i dati raccolti nel formato `.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGChd1FAk5_j"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "print(f\"Versione della libreria TensorFlow = {tf.__version__}\\n\")\n",
        "\n",
        "# Impostiamo il valore del seed della funzione random ad un valore fisso\n",
        "# in questo modo ogni volta che eseguiamo questo notebook genereremo gli stessi numeri\n",
        "SEED = 1337\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# lista delle gesture che abbiamo campionato\n",
        "GESTURES = [\n",
        "    \"punch\",\n",
        "    \"flex\",\n",
        "]\n",
        "\n",
        "SAMPLES_PER_GESTURE = 119\n",
        "\n",
        "NUM_GESTURES = len(GESTURES)\n",
        "\n",
        "# generiamo una codifica one-hot per rappresentare l'output della rete\n",
        "ONE_HOT_ENCODED_GESTURES = np.eye(NUM_GESTURES)\n",
        "\n",
        "inputs = []\n",
        "outputs = []\n",
        "\n",
        "# leggiamo ciascun file csv file e inseriamo i valori corrispondenti negli array inputs e outputs\n",
        "for gesture_index in range(NUM_GESTURES):\n",
        "  gesture = GESTURES[gesture_index]\n",
        "  print(f\"Elaboro l'indice {gesture_index} per la gesture '{gesture}'.\")\n",
        "\n",
        "  output = ONE_HOT_ENCODED_GESTURES[gesture_index]\n",
        "\n",
        "  df = pd.read_csv(\"/content/\" + gesture + \".csv\")\n",
        "\n",
        "  # calcoliamo il numero di esempi per le gesture presenti nei file\n",
        "  num_recordings = int(df.shape[0] / SAMPLES_PER_GESTURE)\n",
        "\n",
        "  print(f\"\\tCi sono {num_recordings} registrazioni della gesture {gesture}.\")\n",
        "\n",
        "  for i in range(num_recordings):\n",
        "    tensor = []\n",
        "    for j in range(SAMPLES_PER_GESTURE):\n",
        "      index = i * SAMPLES_PER_GESTURE + j\n",
        "      # normalizziamo i dati di input tra 0 e 1:\n",
        "      # - i valori di accelerazione variano tra: -4 e +4\n",
        "      # - i valori del giroscopio variano tra: -2000 e +2000\n",
        "      tensor += [\n",
        "          (df['aX'][index] + 4) / 8,\n",
        "          (df['aY'][index] + 4) / 8,\n",
        "          (df['aZ'][index] + 4) / 8,\n",
        "          (df['gX'][index] + 2000) / 4000,\n",
        "          (df['gY'][index] + 2000) / 4000,\n",
        "          (df['gZ'][index] + 2000) / 4000\n",
        "      ]\n",
        "\n",
        "    inputs.append(tensor)\n",
        "    outputs.append(output)\n",
        "\n",
        "# convertiamo le liste nel tipo dato numpy array\n",
        "inputs = np.array(inputs)\n",
        "outputs = np.array(outputs)\n",
        "\n",
        "print(\"Preparazione dei dati completata.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5_61831d5AM"
      },
      "source": [
        "## Prepariamo le coppie input-output per il training mescolando i dati in modo casuale\n",
        "\n",
        "Suddividiamo in modo casuale le coppie input-output separandole in tre insiemi: 60% dei campioni per il training, 20% per la validazione, e 20% per il testing.\n",
        "\n",
        "  - l'insieme di training viene usato per addestrare la rete\n",
        "  - l'insieme di validazione viene usato per misurare le prestazioni del processo di addestramento durante la fase di training\n",
        "  - l'insieme di test viene usato per valutare la rete dopo che il processo è terminato"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfNEmUZMeIEx"
      },
      "source": [
        "# Mescolo in modo casuale i dati di input in modo da preparare in modo\n",
        "# statisticamente più significativo gli insiemi usati per training, validazione e test\n",
        "# https://stackoverflow.com/a/37710486/2020087\n",
        "num_inputs = len(inputs)\n",
        "randomize = np.arange(num_inputs)\n",
        "np.random.shuffle(randomize)\n",
        "\n",
        "# Scambio gli indici consecutivi (0, 1, 2, etc) con i valori di indice randomizzati\n",
        "inputs = inputs[randomize]\n",
        "outputs = outputs[randomize]\n",
        "\n",
        "# Suddivido le registrazioni (gruppi di dati campionati) in tre diversi insiuemi: training, testing e validation\n",
        "TRAIN_SPLIT = int(0.6 * num_inputs)\n",
        "TEST_SPLIT = int(0.2 * num_inputs + TRAIN_SPLIT)\n",
        "\n",
        "inputs_train, inputs_test, inputs_validate = np.split(inputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "outputs_train, outputs_test, outputs_validate = np.split(outputs, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "print(\"Mescolamento e separazione dei campioni completata.\")\n",
        "print(f\"Ci sono {len(inputs_train)} registrazioni nel set di training, {len(inputs_validate)} registrazioni nel set di validation e {len(inputs_test)} in quello di test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train.shape"
      ],
      "metadata": {
        "id": "4c_QIb1nnlkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9g2n41p24nR"
      },
      "source": [
        "## Costruiamo la rete e procediamo con l'addestramento\n",
        "\n",
        "Costruiamo e addestriamo un modello (o rete) [TensorFlow](https://www.tensorflow.org) utilizzando le API di alto livello [Keras](https://www.tensorflow.org/guide/keras).\n",
        "\n",
        "La nostra rete sarà di tipo DNN, con un primo strato di input costituito da 50 neuroni, uno strato intermedio con 15 neuroni e uno strato di output di due neuroni, uno per ciascuna gesture, i cui valori in uscita rappresenteranno la classificazione effettuata dalla rete in termini di valore di probabilità."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGNFa-lX24Qo"
      },
      "source": [
        "# costruzione del modello (rete neurale) e training\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(50, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(15, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(NUM_GESTURES, activation='softmax'))\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "history = model.fit(inputs_train, outputs_train, epochs=600, batch_size=1, validation_data=(inputs_validate, outputs_validate))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUDPvaJE1wRE"
      },
      "source": [
        "## Verifica\n",
        "\n",
        "Visualizziamo un grafico delle prestazioni della rete durante la fase di validazione"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxA0zCOaS35v"
      },
      "source": [
        "### Visualizziamo il grafico della funzione loss\n",
        "\n",
        "Visualizziamo il grafico del  \"*loss*\" per vedere dove il modello smette di migliorare."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFNHXoQzmcM"
      },
      "source": [
        "# definiamo le dimensioni del grafico in modo che sia più grande del valore di default che altrimenti sarebbe (6,4).\n",
        "plt.rcParams[\"figure.figsize\"] = (20,10)\n",
        "\n",
        "# disegnamo i valori della funzione loss, il modello è condfigurato per usare \"mean squared error\" come loss function\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training e validation loss')\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(plt.rcParams[\"figure.figsize\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG3m-VpE1zOd"
      },
      "source": [
        "### Visualizziamo nuovamente il loss spostandoci un poco in avanti rispetto al punto iniziale\n",
        "\n",
        "Visualizziamo lo stesso grafico della cella di codice precedente ma partendo dall'indice 100 in modo da effettuare una sorta di zoom laddove il modello inizia a convergere."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3xT7ue2zovd"
      },
      "source": [
        "\n",
        "SKIP = 100\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRjvkFQy2RgS"
      },
      "source": [
        "### Visualizziamo l'errore medio assoluto\n",
        "\n",
        "Il [Mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) è un'ulteriore metrica per valutare le prestazioni del modello.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBjCf1-2zx9C"
      },
      "source": [
        "# disegno i valori mean absolute error\n",
        "mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b', label='Validation MAE')\n",
        "plt.title('Training e validation mean absolute error')\n",
        "plt.xlabel('Epoche')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guMjtfa42ahM"
      },
      "source": [
        "### Facciamo girare la rete con i dati di test\n",
        "Inseriamo nella rete i dati di test e visualizziamo le previsioni\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3Y0CCWJz2EK"
      },
      "source": [
        "# usiamo la rete per effettuare la classificazione (predictions)\n",
        "predictions = model.predict(inputs_test)\n",
        "\n",
        "# stampo i valori predictions e i valori ouputs attesi\n",
        "print(\"predictions =\\n\", np.round(predictions, decimals=3))\n",
        "print(\"actual =\\n\", outputs_test)\n",
        "\n",
        "# Plot the predictions along with to the test data\n",
        "plt.clf()\n",
        "plt.title('Training data predicted vs actual values')\n",
        "for index in range(0,len(outputs_test)):\n",
        "  plt.plot(index, outputs_test[index].argmax(), 'bo', label='Actual')\n",
        "  plt.plot(index, predictions[index].argmax(), 'r.', label='Predicted')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7DO6xxXVCym"
      },
      "source": [
        "# Convertiamo la Rete addestrata in un Modello Tensor Flow Lite\n",
        "\n",
        "Le istruzioni che seguono convertono il modelllo nel formato TFlite. Viene anche stampata la dimensione in byte del modello."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xn1-Rn9Cp_8"
      },
      "source": [
        "# Conversione del modello nel formato TensorFlow Lite senza quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Salviamo il modello sul file system\n",
        "open(\"gesture_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "import os\n",
        "basic_model_size = os.path.getsize(\"gesture_model.tflite\")\n",
        "print(\"Il modello ha una dimensione di %d bytes\" % basic_model_size)\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykccQn7SXrUX"
      },
      "source": [
        "## Codifichiamo il Modello (Rete) in in un file Header Arduino\n",
        "\n",
        "Le istruzioni che seguono creano un array di byte che contiene il modello TFlite.\n",
        "Il file deve essere importato nello sketch Arduino come nuovo tab.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J33uwpNtAku"
      },
      "source": [
        "!echo \"const unsigned char model[] = {\" > /content/model.h\n",
        "!cat gesture_model.tflite | xxd -i      >> /content/model.h\n",
        "!echo \"};\"                              >> /content/model.h\n",
        "\n",
        "import os\n",
        "model_h_size = os.path.getsize(\"model.h\")\n",
        "print(f\"Il file Header, model.h, ha una dimensione di {model_h_size:,} bytes.\")\n",
        "print(\"\\nApri il pannello (effettua evenetualmente il refresh). Effettua il download the file (doppio clic o menu di riga).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eSkHZaLzMId"
      },
      "source": [
        "# Classifichiamo i Dati IMU\n",
        "\n",
        "Ora possiamo eseguire il modello su un Arduino Nano 33 BLE Sense per interpretare i dati dell'accelerometro e del giroscopio.\n"
      ]
    }
  ]
}